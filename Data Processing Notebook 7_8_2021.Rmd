---
title: "R Notebook"
author: "Tom Richebacher"
date: "7/11/2023"
output: html_notebook
---

```{r call-libraries, warning=TRUE}

R_LIBS_USER = "C:/Users/Tom/OneDrive/R_code/win-library/4.2"

library(formatR)
library(HiClimR)
library(lintr)
library(here)
library(data.table)
library(caret)
library(ggplot2)
library(xgboost)
library(gmodels)
library(MLmetrics)
library(janitor)
library(partykit)
#library(xlsx)
library(pROC)  #for ROC curve
library(stringr)
library(DataExplorer)
library(smbinning)
library(funModeling)
library(SmartEDA)
library(fastDummies)
library(rattle)
library(rpart.plot)
library(RColorBrewer)

library(doParallel)
detectCores()

registerDoParallel(cores = 8)

#for speed testind a data dublication function
#dt_dup1 <- rbindlist(rep(list(DT), 10))
```

## [Initialize global variables]{.underline}

```{r initialize-global-variables, warning=TRUE}
options(scipen = 999)
use.integer64 = FALSE
setNumericRounding(2)

#"REG" = regression, "B_CLASS" = binary class, "M_CLASS" = multiclass
ANALYSIS_TYPE = 'B_CLASS'
FILES = '1'
Project = "Credit"
report_path = 'C:/Users/trich/OneDrive/R_code/credit'
data_path = 'C:/Users/trich/OneDrive/R_code/credit'
```

# [Get Files:]{.underline}

## Read data

```{r message=TRUE, warning=TRUE}
read_data <- function(filename) {
       fread(filename,
                # Set separator as comma
                sep = ",",
                # Read all rows - use nrows = xxx to read partial file
                nrows = -1,
                # Check column names for validity
                check.names = TRUE,
                #read random sample
                #n = 50000,
                # Set header as first row
                header = TRUE,
                # treat all integer columns as 64-bit integers
                integer64 = 'numeric',
                #Use quote to specify character used to quote strings in the file
                #quote = "'",
                #specify the possible string representations of missing values
                na.strings = c("NA", "N/A", "null", "", "unknown"))
 }

# Call function to read in data files
if (FILES == '1') {
  DT <- read_data(paste0(data_path,'/DT.csv'))
  saveRDS(DT, paste0(data_path,'/DT.Rds'))
} else if (FILES == '2') {
  train <- read_data("train.csv")
  train[, file := "train"]
  saveRDS(train, paste0(data_path,'/train.Rds'))
  test <- read_data("test.csv")
  test[, file := "test"]
  saveRDS(test, paste0(data_path,'/test.Rds'))
}

rm(read_data)
```

## Stack train and test file

```{r eval=FALSE, include=FALSE}
if (FILES == 2) {

    # function to identify column header differences
    get_feature_names <- function(file1, file2) {
        # find the names that are common between the tables
        var_names <- intersect(names(file1), names(file2))
        # find columns different in file1
        var_names_file1 <- setdiff(names(file1), names(file2))
        # find columns different in file 2
        var_names_file2 <- setdiff(names(file2), names(file1))
        # show all differences between the two files
        col_diff <- paste0(var_names_file1, var_names_file2)
        return(col_diff)
    }

    # return column header difference
    get_feature_names(train, test)

    # #assign Id if needed setnames(train, 'train_id', 'Id') setnames(test, 'test_id', 'Id')

    # stack train and test
    DT <- rbind(train, test, fill = TRUE, use.names = TRUE)
    rm(train, test, get_feature_names)
}

```

###### Join Files

```{r eval=FALSE, include=FALSE}

DT <-  merge(DT, people, by = 'people_id', all.x = TRUE)
DT$Id <- seq.int(nrow(DT))
 
rm(people)
```

###### Sample File

```{r Sample-file, eval=FALSE, include=FALSE}
DT_samp <- DT[sample(.N, 30000)]
```

## Create record Id

```{r}
#create index
DT[, Id := as.integer(.I)]

#move index to 1st column
setcolorder(DT, c("Id", colnames(DT)[1:(ncol(DT) - 1)]))
```

# [Column Work]{.underline}

## Clean column headers

```{r eval=FALSE, include=FALSE}
# identify non standard column headers
# Define a regex pattern for non-standard column names

non_standard_pattern <- "^[^A-Za-z_].*$"

# Identify non-standard column names
non_standard_cols <- names(DT)[grepl(non_standard_pattern, names(DT))]

# Print the non-standard column names
print(non_standard_cols)

# Clean column names
setnames(DT, clean_names(names(DT)))

setnames(DT, old = c("a", "d"), new = c("anew", "dnew"))

```

## distribution Report

```{r paged.print=TRUE}
# Table with basic statistics
smbinning.eda(DT,rounding = 3)$eda 
```

## Change Column Classes

```{r eval=FALSE, include=FALSE}
#individual var
DT[, target := as.factor(target)]

#by specific vars
conv_vars <- c("return_dollar", "product_id")

#by column text spring
conv_vars <- grep("(cat|bin)", names(DT), value = TRUE)

#by all vars of a specific class
conv_vars <- colnames(DT[, .SD, .SDcols = sapply(DT, is.numeric)])

#identify binaries to convert
conv_vars <- names(Filter(function(x)uniqueN(na.omit(x)) <= 2 & max(x) == 1, DT))

#********************************************************************************#
#do actual conversion
DT[, (conv_vars) := lapply(.SD, as.numeric), .SDcols = conv_vars]
#********************************************************************************#
#*
rm(conv_vars)
```

## Delete unnecessary columns

```{r eval=FALSE, include=FALSE}

#delete columns with one value
rm_cols <- colnames(DT)[sapply(DT, function(x) length(unique(x))) == 1]

#delete specific cols
rm_cols <- c("V1", "id")

if (length(rm_cols) > 0) {
  DT[, (rm_cols) := NULL]
}

rm(rm_cols)
```

# [Row Work]{.underline}

## Get % missing

```{r eval=FALSE, include=FALSE}
# Calculate the number of missing values in each row

DT$row_miss_orig <- dt[, rowSums(is.na(DT))]

freq(DT$row_miss_orig)

# filter out records
dt[x <= 3]
```

###### Omit rows where either vars 'x' or 'y' have NA

```{r eval=FALSE, include=FALSE}
# select columns
omit_row <- c("x", "y")

# see how many records are left
DT[complete.cases(DT[, ..omit_row]), ]
```

# Target Prep

## Target Analysis & Prep

```{r}
# assign target name
setnames(DT, "default", "target")

# move target to 1st column
setcolorder(DT, c("target", setdiff(names(DT), "target")))

# target distribution
if (ANALYSIS_TYPE != "REG") {
    DT[, .(.N), by = .(target)]
    plot_bar(DT$target)
} else {
    plot_histogram(DT$target)
}

# rename target value when binary
if (ANALYSIS_TYPE == "B_CLASS") {
DT[, target := ifelse(target == 1, "HaveNot", ifelse(target == 2, "Have", NA))]
}

# remove missing target records
DT[!is.na(target)]
```

###### Normalize Target Variable

```{r eval=FALSE, include=FALSE}
DT[, target := log(target + 1)]
```

## Append identifier to orginal column headers

```{r}
# get names to exclude
exclude_columns <- c("target", "Id")

# Get original data columnns
orig_columns <- setdiff(colnames(DT), exclude_columns)

# define the suffix
suffix = "_orig"

# Append the suffix to the selected columns
setnames(DT, old = orig_columns, new = paste0(orig_columns, suffix))

rm(orig_columns, exclude_columns, suffix)
```

# Create table with data that bypasses the analysis

```{r include=FALSE}
# identify vars for bypass table
mov_var = c("target", "Id")

# create bypass table
DT_tar <- DT[, .SD, .SDcols = mov_var]

# save bypass table
saveRDS(DT_tar, paste0(data_path, "/DT_tar.Rds"))

# remove bypass table unless needed
rm(mov_var, DT_tar)
gc()
```

# Data Exploration

## View data profile report

```{r include=FALSE}

# create in depth data report
create_report(DT, y = "target", report_title = paste0(Project, " Data Report"), output_file = paste0(Project, " Profile Report"), output_dir = report_path)
```

## Create DT profile report with target

```{r paged.print=TRUE}
# analysis of categorical data
ExpCatStat(DT[, -c("Id")],Target = "target", 
           result = "Stat",
           clim = 10,                  #max levels of cat vars allowed
           nlim = 10,                  #maximum unique values for num vars
           bins = 10,                  #max number of bins
           Pclass = "Have",
           plot = FALSE,
           top = 20,
           Round = 2)
```

Information Value of categorical vars

```{r}
ExpCatStat(DT[, -c("Id")],Target = "target",
                            result = "IV",
                            clim = 5,          #max # of cats allowed
                            nlim = 10,         # of levels for num vars
                            bins = 10,         #max # of bins for cat & num vars
                            Pclass = "Have")
```

\# analysis of numeric data

```{r}
ExpNumStat(DT[, -c("Id")],
                           by = "G",
                           gp = "target",
                           Qnt = NULL,
                           Nlim = 10,
                           MesofShape = 2,
                           Outlier = TRUE,
                           round = 2,
                           weight = NULL,
                           dcast = FALSE,
                           val = NULL)
```

Outlier analysis

```{r eval=FALSE, include=FALSE}
# #outlier analysis
# num_cols <- colnames(DT)[sapply(DT, is.numeric) & names(DT) != "Id"]
# 
# outlier_analysis <- ExpOutliers(
# DT,
# varlist = num_cols,
# method = "boxplot",
# treatment = NULL,
# capping = c(0.05, 0.95),
# outflag = TRUE)
```
